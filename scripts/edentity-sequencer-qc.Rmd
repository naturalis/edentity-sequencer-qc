---
header-includes:
   - \usepackage{color}
title: \textcolor{red}{eDentity Sequencer Qc}

date: "2024-10-23"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,  message=FALSE,warning=FALSE)
```


## 1.1.1 Percantage of bases >= Q30 
```{r}

# function to fix misssing commas
fix_csv_commas <- function(input_file, output_file) {
  #  Read the CSV file line by line
  lines <- readLines(input_file)
  
  # Fix lines that have missing commas
  fixed_lines <- sapply(lines, function(line) {
    num_commas <- length(strsplit(line, ",")[[1]]) - 1
    
    # Assuming each row should have 2 commas (for 3 columns)
    if (num_commas == 1) {
      return(paste0(line, ","))   # Add one missing comma
    } else if (num_commas == 0) {
      return(paste0(line, ",,"))  # Add two missing commas
    } else {
      return(line)  # If correct, no change
    }
  })
  
  # Write the fixed lines to the output file
  writeLines(fixed_lines, output_file)
  
  # Return confirmation or any additional actions if needed
  message("CSV has been fixed and saved to: ", output_file)
}

# Example usage:
# fix_csv_commas("input_file.csv", "fixed_file.csv")

#fix missing comma

fix_csv_commas("../results/elements-1.1.1-qc.txt", "../results/elements-1.1.1-qc-fixed.csv")
fix_csv_commas("../results/illumina-1.1.1-qc.txt", "../results/illumina-1.1.1-qc-fixed.csv")


```


```{r}

#extract average q30 fraction
get_mean_q30 <- function(q30_file){
    # read the data
    df <- read.csv(q30_file, header = F)
    
    colnames(df)[1:3] <- c("file", "n_reads", "q30.fraction")
    
    df <- subset(df, select = c("file", "n_reads", "q30.fraction"))
    df <- na.omit(df)
    df$scaled_q30 <- df$n_reads * df$q30.fraction
    
    sum_scaled <- sum(df$scaled_q30) / sum(df$n_reads)
    
    
    return(sum_scaled)
}


q30_df<- data.frame(
        Illumina = get_mean_q30("../results/illumina-1.1.1-qc-fixed.csv"),
        Elements = get_mean_q30("../results/elements-1.1.1-qc-fixed.csv"))

knitr::kable(q30_df,  align="lr", digits = 2)
```



## 1.1.2 Read Length Retension after Q30 Trimming (Percentage)
```{r}
get_length_retention <- function(untrimmed_stast_file, trimmed_stats_file) {
  
  
  len_stats <- read.csv(untrimmed_stast_file, sep = "\t")
  trimmed_len_stats <- read.csv(trimmed_stats_file, sep = "\t")
  
  return(
    mean(as.numeric(na.omit(trimmed_len_stats$avg_len))) / 
      mean(as.numeric(na.omit(len_stats$avg_len))) * 100
    )
}


length_df <- data.frame(Illumina = get_length_retention(
                                      "../results/illumina-stats.tsv",
                                      "../results/trimmed-illumina-stats.tsv"),
                        
                        Elements = get_length_retention(
                                      "../results/elements-stats.tsv",
                                      "../results/trimmed-elements-stats.tsv"))

knitr::kable(length_df,align="lr", digits = 2)
```


## 1.2.1 Hommopolymer Accuracy
```{r}
decay <- function(decay_file){
  
  accuracy <- read.csv(decay_file, header = FALSE)
  colnames(accuracy) <- c("file", "total_reads", "average_decay")
  return(
    mean(accuracy$average_decay)
    )
}

decay_df <- data.frame(
  Illumina = decay("../results/illumina-1.2.1-homopolymer_decay.csv"),
  Elements = decay("../results/elements-1.2.1-homopolymer_decay.csv")
)

knitr::kable(decay_df,align="lr", digits = 2)
```
## 1.2.2 Demultiplexing Efficiency (Percentage)

```{r}
# Issue:
  # How to get the undetermined in elements: empty with > 1000 reads ??

demux <- read.csv("../results/illumina-1.2.2-demux.csv")
total_reads <- sum(demux$Nreads) # should empty be part of totals ?
n_demultiplexed <-  sum(demux[demux$Category != "Undetermined",]$Nreads)
efficiency <- n_demultiplexed / total_reads * 100
demult_df <- data.frame(illumina = efficiency)

knitr::kable(demult_df, align="lr", digits = 2)
```

## 1.2.3 PhiX Control performance

ADD ILLUMINA

### Elements


PhiX Error Rate: 0.022586

PhiX Alignment Rate: 0.6086

PhiX Coverage Uniformity:

  - Coefficient of Variation: 0.4593
  
  - Percentage within Â±20% of mean coverage: 0.4330

Additional Information:

  - Total Reads: 792
  
  - Mapped Reads: 482
  
  - Mean Coverage: 26.73
  
  - Coverage Range: 1 - 70


## 1.2.4 Duplicate Read Rate (Percentage)
Percentage of duplicate reads in in a standard non-amplified library

Extract Phix reads only (reads that mapped to the ref)

```{r}

# Issues:
  # which files were standard non-amplified library ???

average_duplicate_ratio <- function(dedup_file){
  
    duplicates = read.csv(dedup_file, header = F)
    colnames(duplicates) <- c("file_name", "total_reads",
                            "unique_reads","duplicate_reads",
                            "duplicate_rate","duplicate_percentage")
    return(mean(duplicates$duplicate_percentage))
    }


dedup_df <- data.frame(Illumina = average_duplicate_ratio(
                                                "../results/illumina-1.2.4-dedup.csv"),
                       Elements = average_duplicate_ratio(
                                                "../results/elements-1.2.4-dedup.csv"))
knitr::kable(dedup_df, align="lr", digits = 2)
```

## 1.2.5 GC Bias 
Deviation of coverage in GC-rich regions compared to AT-rich regions

```{r}
gc_bias <- function(gc_bias_file){
    gc_df <- read.csv("../results/elements-1.2.5.csv")
    return(
     mean(gc_df$Average.Coverage))
  }

gc_bias_coverage = data.frame(
    Elements = gc_bias("../results/elements-1.2.5.csv")
    # illumina coming
)

knitr::kable(gc_bias_coverage,align="lr", digits = 2)
```









